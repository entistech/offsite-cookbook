{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f1d75ef-75a5-4c3d-ba59-dbf68d3224cb",
     "showTitle": false,
     "title": ""
    },
    "id": "izNeUi--hSSA"
   },
   "source": [
    "# Semantic Search with Pinecone and OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "677cda8c-ff10-4539-b6be-e9a7c9e786a3",
     "showTitle": false,
     "title": ""
    },
    "id": "LI76-BMFhUmS"
   },
   "source": [
    "In this guide you will learn how to use the OpenAI Embedding API to generate language embeddings, and then index those embeddings in the Pinecone vector database for fast and scalable vector search.\n",
    "\n",
    "This is a powerful and common combination for building semantic search, question-answering, threat-detection, and other applications that rely on NLP and search over a large corpus of text data.\n",
    "\n",
    "The basic workflow looks like this:\n",
    "\n",
    "**Embed and index**\n",
    "\n",
    "* Use the OpenAI Embedding API to generate vector embeddings of your documents (or any text data).\n",
    "* Upload those vector embeddings into Pinecone, which can store and index millions/billions of these vector embeddings, and search through them at ultra-low latencies.\n",
    "\n",
    "**Search**\n",
    "\n",
    "* Pass your query text or document through the OpenAI Embedding API again.\n",
    "* Take the resulting vector embedding and send it as a query to Pinecone.\n",
    "* Get back semantically similar documents, even if they don't share any keywords with the query.\n",
    "\n",
    "![Architecture overview](https://files.readme.io/6a3ea5a-pinecone-openai-overview.png)\n",
    "\n",
    "Let's get started..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41e2f210-f5f0-456c-98b7-827054e50222",
     "showTitle": false,
     "title": ""
    },
    "id": "nXzzYE0hhU64"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d52b58fe-12f4-47dd-8829-4c7cdf237f5e",
     "showTitle": false,
     "title": ""
    },
    "id": "FNk3hfyAtRNj"
   },
   "source": [
    "We first need to setup our environment and retrieve API keys for OpenAI and Pinecone. Let's start with our environment, we need HuggingFace *Datasets* for our data, and the OpenAI and Pinecone clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f6d4235-40d6-488e-8f03-979f262b86af",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SGQoz_JmtRNh",
    "outputId": "389c79fc-2ee9-452b-fc58-9598899090c2"
   },
   "outputs": [],
   "source": [
    "!pip install -qU pinecone-client openai datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3069ab3-afae-4f03-912c-3e7c0c7a64a7",
     "showTitle": false,
     "title": ""
    },
    "id": "IMp0TQ24tRNm"
   },
   "source": [
    "### Creating Embeddings\n",
    "\n",
    "Then we initialize our connection to OpenAI Embeddings *and* Pinecone vector DB. Sign up for an API key over at [OpenAI](https://beta.openai.com/signup) and [Pinecone](https://app.pinecone.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa29a743-10eb-476f-b51a-6bf53f385d1f",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yo5uw4sPtRNn",
    "outputId": "92914528-696d-4598-dbb3-04457a0eba86"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"OPENAI_API_KEY\"\n",
    "# get API key from top-right dropdown on OpenAI website\n",
    "\n",
    "openai.Engine.list()  # check we have authenticated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33d21c5f-c2d2-4ff5-b5fa-5b2f351d9b19",
     "showTitle": false,
     "title": ""
    },
    "id": "pw8cbO3HtRNo"
   },
   "source": [
    "We can now create embeddings with the OpenAI Ada similarity model like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d21790d8-1168-4c63-bb4a-ab6045821a97",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hg0yIGu3tRNo",
    "outputId": "58fb10c1-53f0-4dd1-b0fd-14491d4decf3"
   },
   "outputs": [],
   "source": [
    "MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=MODEL\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "686e3829-4875-4d8c-8f24-daa054b30dfb",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Egz35DjtRNo",
    "outputId": "78c4c022-d3a8-4fa7-8fa8-59c45eca1298"
   },
   "outputs": [],
   "source": [
    "print(f\"vector 0: {len(res['data'][0]['embedding'])}\\nvector 1: {len(res['data'][1]['embedding'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cf0818f-178d-4836-8838-bf6b543a3045",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZguN6obBtRNp",
    "outputId": "bd20d4be-0772-4383-9d1e-9960d8b5f183"
   },
   "outputs": [],
   "source": [
    "# we can extract embeddings to a list\n",
    "embeds = [record['embedding'] for record in res['data']]\n",
    "len(embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9453704-57cb-4184-982f-ecfefbd83676",
     "showTitle": false,
     "title": ""
    },
    "id": "U4WJwy58tRNp"
   },
   "source": [
    "Next, we initialize our index to store vector embeddings with Pinecone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1804085-4f8b-47dc-af0c-f46e7117c2b8",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OnyoBu-BRNOs",
    "outputId": "4d40b553-4ff2-4336-baab-24ff6424fead"
   },
   "outputs": [],
   "source": [
    "len(embeds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "134d1e56-4e21-4788-9436-41257760aaff",
     "showTitle": false,
     "title": ""
    },
    "id": "I2KLRbN-tRNq"
   },
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "index_name = 'semantic-search-openai'\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "pinecone.init(\n",
    "    api_key=\"PINECONE_API_KEY\",\n",
    "    environment=\"PINECONE_ENVIRONMENT\"  # find next to api key in console\n",
    ")\n",
    "# check if 'openai' index already exists (only create index if not)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(index_name, dimension=len(embeds[0]))\n",
    "# connect to index\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4f9ae66-d030-4760-a0fa-3f6f7d185a00",
     "showTitle": false,
     "title": ""
    },
    "id": "TLCLmeZRtRNq"
   },
   "source": [
    "## Populating the Index\n",
    "\n",
    "Now we will take 1K questions from the TREC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed5fb310-bdaf-44a6-8f8e-c67b9da10d3b",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JiSfCTK-lhXx",
    "outputId": "bcb82771-a0d5-4c63-d2ad-69a963f93620"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the first 1K rows of the TREC dataset\n",
    "trec = load_dataset('trec', split='train[:1000]')\n",
    "trec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30f67f99-00e4-47ca-8333-7e052e84776b",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2m7a_zl8lt2e",
    "outputId": "7e2bc141-27bf-4580-c632-642a65c652d8"
   },
   "outputs": [],
   "source": [
    "trec[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cfac41b-485c-49fe-9506-9f4306722618",
     "showTitle": false,
     "title": ""
    },
    "id": "sJwnszP0ljN6"
   },
   "source": [
    "Then we create a vector embedding for each phrase using OpenAI, and `upsert` the ID, vector embedding, and original text for each phrase to Pinecone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70f0114b-f7fa-4266-ba9f-afd890d79856",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "0d73abb4e43144b281b35cd7b26f4197",
      "74e7f7ea3b0f45eca68d2af7e6c15957",
      "d58f34488c9f433cafbbe72803096267",
      "a791ec194e974ea6a4e18b4bc1c5bc49",
      "de16af8ed7f84ce3a8b20b03f04ccd58",
      "cc26431b7f64491fbc5189b6c88744b9",
      "1b6caaee4ca144cbbc4650924ea34b27",
      "0e9afbd797ee4d17a085c90c7b27bfc9",
      "cfcfd1cf66a942788a6b9553a41c6c8e",
      "3977aa60e81a4fb980087c8b479fd10a",
      "b600da6475f34fbab3e249be8929591b"
     ]
    },
    "id": "B80PgNyytRNq",
    "outputId": "57bfa165-72f2-46ca-9e51-fd7d0fb23b07"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "count = 0  # we'll use the count to create unique IDs\n",
    "batch_size = 32  # process everything in batches of 32\n",
    "for i in tqdm(range(0, len(trec['text']), batch_size)):\n",
    "    # set end position of batch\n",
    "    i_end = min(i+batch_size, len(trec['text']))\n",
    "    # get batch of lines and IDs\n",
    "    lines_batch = trec['text'][i: i+batch_size]\n",
    "    ids_batch = [str(n) for n in range(i, i_end)]\n",
    "    # create embeddings\n",
    "    res = openai.Embedding.create(input=lines_batch, engine=MODEL)\n",
    "    embeds = [record['embedding'] for record in res['data']]\n",
    "    # prep metadata and upsert batch\n",
    "    meta = [{'text': line} for line in lines_batch]\n",
    "    to_upsert = zip(ids_batch, embeds, meta)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=list(to_upsert))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a69ea34f-ff3a-407a-aba9-91cf1a2aa8bc",
     "showTitle": false,
     "title": ""
    },
    "id": "iW_iM_M_tRNr"
   },
   "source": [
    "---\n",
    "\n",
    "# Querying\n",
    "\n",
    "With our data indexed, we're now ready to move onto performing searches. This follows a similar process to indexing. We start with a text `query`, that we would like to use to find similar sentences. As before we encode this with OpenAI's text similarity Babbage model to create a *query vector* `xq`. We then use `xq` to query the Pinecone index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b9f0d4f-e4a9-4302-b28c-961e6a3b3b3f",
     "showTitle": false,
     "title": ""
    },
    "id": "k80ASNMqtRNr"
   },
   "outputs": [],
   "source": [
    "query = \"What caused the 1929 Great Depression?\"\n",
    "\n",
    "xq = openai.Embedding.create(input=query, engine=MODEL)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e2878cb-fb45-4b06-86c0-7f1bc4c232b5",
     "showTitle": false,
     "title": ""
    },
    "id": "RxCKv-UktRNs"
   },
   "source": [
    "Now query..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b31124f4-bf87-49bb-8e02-06d6ed61cf42",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_cY3_rXytRNs",
    "outputId": "539ac857-9980-4156-9344-4224cb54ff26"
   },
   "outputs": [],
   "source": [
    "res = index.query([xq], top_k=5, include_metadata=True)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b041e8ce-4ad9-41e2-8180-3cc98011b2db",
     "showTitle": false,
     "title": ""
    },
    "id": "I2iydlXVjmMZ"
   },
   "source": [
    "The response from Pinecone includes our original text in the `metadata` field, let's print out the `top_k` most similar questions and their respective similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0de470d-1d9e-4f1f-8468-9edfbc568f59",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WT1L2ogHjiO-",
    "outputId": "50ecca3e-7d31-414e-b59a-7725a22ed864"
   },
   "outputs": [],
   "source": [
    "for match in res['matches']:\n",
    "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ebe5712-b216-454d-b9c1-35cfc7ab252a",
     "showTitle": false,
     "title": ""
    },
    "id": "wu7LmvmIjqPq"
   },
   "source": [
    "Looks good, let's make it harder and replace *\"depression\"* with the incorrect term *\"recession\"*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d2e8f49-aba0-440e-9d21-780297a0c59e",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SaT9yMj7jq0u",
    "outputId": "2841ae2b-957f-4ed2-8260-c89d0f2cbc8f"
   },
   "outputs": [],
   "source": [
    "query = \"What was the cause of the major recession in the early 20th century?\"\n",
    "\n",
    "# create the query embedding\n",
    "xq = openai.Embedding.create(input=query, engine=MODEL)['data'][0]['embedding']\n",
    "\n",
    "# query, returning the top 5 most similar results\n",
    "res = index.query([xq], top_k=5, include_metadata=True)\n",
    "\n",
    "for match in res['matches']:\n",
    "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fb460bf-66a8-4ac0-8d81-2f14177f4fb0",
     "showTitle": false,
     "title": ""
    },
    "id": "FXFhFri0jzkG"
   },
   "source": [
    "And again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8daa9ab-780f-497a-add5-ae7c7cece469",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOEvNweOj1AH",
    "outputId": "9e5deb27-909b-4d88-b000-46a9e3b6486f"
   },
   "outputs": [],
   "source": [
    "query = \"Why was there a long-term economic downturn in the early 20th century?\"\n",
    "\n",
    "# create the query embedding\n",
    "xq = openai.Embedding.create(input=query, engine=MODEL)['data'][0]['embedding']\n",
    "\n",
    "# query, returning the top 5 most similar results\n",
    "res = index.query([xq], top_k=5, include_metadata=True)\n",
    "\n",
    "for match in res['matches']:\n",
    "    print(f\"{match['score']:.2f}: {match['metadata']['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0733f0a6-a68d-433a-b699-11a7208334fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Looks great, our semantic search pipeline is clearly able to identify the meaning between each of our queries and return the most semantically similar questions from the already indexed questions.\n",
    "\n",
    "Once we're finished with the index we delete it to save resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45e1df54-b449-436e-9a60-3867dd8372e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pinecone.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc102764-4148-447b-a522-59c62beb0010",
     "showTitle": false,
     "title": ""
    },
    "id": "ItsvY1lej6dz"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Semantic_Search",
   "notebookOrigID": 1572001650642082,
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d73abb4e43144b281b35cd7b26f4197": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_74e7f7ea3b0f45eca68d2af7e6c15957",
       "IPY_MODEL_d58f34488c9f433cafbbe72803096267",
       "IPY_MODEL_a791ec194e974ea6a4e18b4bc1c5bc49"
      ],
      "layout": "IPY_MODEL_de16af8ed7f84ce3a8b20b03f04ccd58"
     }
    },
    "0e9afbd797ee4d17a085c90c7b27bfc9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b6caaee4ca144cbbc4650924ea34b27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3977aa60e81a4fb980087c8b479fd10a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74e7f7ea3b0f45eca68d2af7e6c15957": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc26431b7f64491fbc5189b6c88744b9",
      "placeholder": "​",
      "style": "IPY_MODEL_1b6caaee4ca144cbbc4650924ea34b27",
      "value": "100%"
     }
    },
    "a791ec194e974ea6a4e18b4bc1c5bc49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3977aa60e81a4fb980087c8b479fd10a",
      "placeholder": "​",
      "style": "IPY_MODEL_b600da6475f34fbab3e249be8929591b",
      "value": " 32/32 [00:16&lt;00:00,  2.11it/s]"
     }
    },
    "b600da6475f34fbab3e249be8929591b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc26431b7f64491fbc5189b6c88744b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfcfd1cf66a942788a6b9553a41c6c8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d58f34488c9f433cafbbe72803096267": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e9afbd797ee4d17a085c90c7b27bfc9",
      "max": 32,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cfcfd1cf66a942788a6b9553a41c6c8e",
      "value": 32
     }
    },
    "de16af8ed7f84ce3a8b20b03f04ccd58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
