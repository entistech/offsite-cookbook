{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3549bc07-d8d8-4c6f-8617-c72f51066b4a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Retrieval Augmentation for GPT-4 using Pinecone\n",
    "\n",
    "#### Fixing LLMs that Hallucinate\n",
    "\n",
    "In this notebook we will learn how to query relevant contexts to our queries from Pinecone, and pass these to a GPT-4 model to generate an answer backed by real data sources.\n",
    "\n",
    "GPT-4 is a big step up from previous OpenAI completion models. It also exclusively uses the `ChatCompletion` endpoint, so we must use it in a slightly different way to usual. However, the power of the model makes the change worthwhile, particularly when augmented with an external knowledge base like the Pinecone vector database.\n",
    "\n",
    "Required installs for this notebook are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41feaeb8-0cf1-4b34-8deb-a52737f565af",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_HDKlQO5svqI",
    "outputId": "4a57df82-5e46-4b60-f0c7-c408e3d0f5b0"
   },
   "outputs": [],
   "source": [
    "!pip install -qU bs4 tiktoken openai langchain pinecone-client[grpc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc9dec79-f292-4e10-84b8-08a12404a259",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "193bcff5-73f3-45bd-9dc0-28e6c5e3704f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "In this example, we will download the LangChain docs from [langchain.readthedocs.io/](https://langchain.readthedocs.io/latest/en/). We get all `.html` files located on the site like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf0a8fb0-b726-4052-941f-26ed3c442584",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xo9gYhGPr_DQ",
    "outputId": "f1b00acf-b7f0-48e3-abf6-8b0d8a86ffd2"
   },
   "outputs": [],
   "source": [
    "!wget -r -A.html -P rtdocs https://python.langchain.com/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fc71915-6db7-401b-96eb-0a18c2b5ec2d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This downloads all HTML into the `rtdocs` directory. Now we can use LangChain itself to process these docs. We do this using the `ReadTheDocsLoader` like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e80d057-dbca-45d0-8bda-73d347d3aa98",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n40_0MtlsKgM",
    "outputId": "e0978f3f-2b1a-4d95-c8c6-5e73a5f35f56"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import ReadTheDocsLoader\n",
    "\n",
    "loader = ReadTheDocsLoader('rtdocs')\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba7633ec-ddc9-444d-9f99-24c48b394b4c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This leaves us with hundreds of processed doc pages. Let's take a look at the format each one contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b738e824-5232-4269-8e81-8afbcd8e8202",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "642e571c-a28d-4d08-8160-f2e21614f826",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We access the plaintext page content like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d4c7b72-762a-4c40-be3a-a8b8cf85f724",
     "showTitle": false,
     "title": ""
    },
    "id": "OcIkny_6xiZJ"
   },
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "215c1959-5872-4092-bf1e-92762c5a2e9f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(docs[5].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "126bee32-1e89-4335-95ea-3de5f8ad8434",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can also find the source of each document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29a38da3-4cd6-4ee0-bb64-5962ff938983",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "docs[5].metadata['source'].replace('rtdocs/', 'https://')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3f336b5-0a80-4f44-9c15-81f6bd3418c4",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F0tUQRxtzqF0",
    "outputId": "a7a9b799-98cb-41a2-a696-fc9f00579773"
   },
   "outputs": [],
   "source": [
    "data[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21e86e2e-6c89-4ff5-88bd-8a9f8c9a40bf",
     "showTitle": false,
     "title": ""
    },
    "id": "ouY4rcx7z2oa"
   },
   "source": [
    "It's pretty ugly but it's good enough for now. Let's see how we can process all of these. We will chunk everything into ~400 token chunks, we can do this easily with `langchain` and `tiktoken`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9596efa2-e04e-4cfb-b01d-d789290094b7",
     "showTitle": false,
     "title": ""
    },
    "id": "Rb7KxUqYzsuV"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('p50k_base')\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da5adfe6-09f7-4772-814a-4d703cd4dea7",
     "showTitle": false,
     "title": ""
    },
    "id": "OKO8e3Dp0dQS"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=20,\n",
    "    length_function=tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5ccf6f1-e4f1-44ca-b46b-152d85a10de7",
     "showTitle": false,
     "title": ""
    },
    "id": "bLdvW8eq06Zd"
   },
   "source": [
    "Process the `data` into more chunks using this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9fa61b8-68b9-45e9-8507-5b53e31ee955",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "fe4aa5160ef74ecd820f9c6f7de035a0",
      "8f0edead487948358efe478a01316209",
      "bcd3e274345a44dc950890c1fa1026a7",
      "153f898146264d50b77b5ef23db92408",
      "30d7236e54844058b7c76404e1f2ccb8",
      "348fe1bd02ed4dca8df422031d1184f6",
      "157f79e1ecf0423393cb15dcd2e66996",
      "a43a7db5cab149b3a8aeef23d3fb936f",
      "865d0f1e70cc4889aaf91cf1ad82b909",
      "1bed5d4ebf054e80b4d63d6f8a2593d8",
      "04fd6e9cebaa4c9287d16cb8c861c8a3"
     ]
    },
    "id": "uOdPyiAQ0uWs",
    "outputId": "b1d00544-a432-4a41-a68e-59a0f9825070"
   },
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for idx, record in enumerate(tqdm(data)):\n",
    "    texts = text_splitter.split_text(record['text'])\n",
    "    chunks.extend([{\n",
    "        'id': str(uuid4()),\n",
    "        'text': texts[i],\n",
    "        'chunk': i,\n",
    "        'url': record['url']\n",
    "    } for i in range(len(texts))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "daab88a9-0116-4985-a4a3-134bfd2b162b",
     "showTitle": false,
     "title": ""
    },
    "id": "JegURaAg2PuN"
   },
   "source": [
    "Our chunks are ready so now we move onto embedding and indexing everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08f321e5-2ac7-455b-a8a0-0f7424299d53",
     "showTitle": false,
     "title": ""
    },
    "id": "zGIZbQqJ2WBh"
   },
   "source": [
    "## Initialize Embedding Model\n",
    "\n",
    "We use `text-embedding-ada-002` as the embedding model. We can embed text like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "020c37f9-4994-4d00-8a5c-bbbe60565cad",
     "showTitle": false,
     "title": ""
    },
    "id": "kteZ69Z5M55S"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# initialize openai API key\n",
    "openai.api_key = \"sk-...\"  #platform.openai.com\n",
    "\n",
    "embed_model = \"text-embedding-ada-002\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[\n",
    "        \"Sample document text goes here\",\n",
    "        \"there will be several phrases in each batch\"\n",
    "    ], engine=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43a1b3ac-cf48-4106-af88-2e88c9ca51b5",
     "showTitle": false,
     "title": ""
    },
    "id": "aNZ7IWekNLbu"
   },
   "source": [
    "In the response `res` we will find a JSON-like object containing our new embeddings within the `'data'` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aaaf26b8-09cd-4ab3-8673-b16ae30c4932",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esagZj6iNLPZ",
    "outputId": "0e8b59d7-6c26-4fbf-e093-56d35aa18ab5"
   },
   "outputs": [],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d50c6a1c-515a-419e-9da1-1e24906c5bca",
     "showTitle": false,
     "title": ""
    },
    "id": "zStnHFpkNVIU"
   },
   "source": [
    "Inside `'data'` we will find two records, one for each of the two sentences we just embedded. Each vector embedding contains `1536` dimensions (the output dimensionality of the `text-embedding-ada-002` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf26a1ab-ecf7-4a7b-8676-5eff77ba5046",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVoP9VcINWAC",
    "outputId": "36329c98-2191-4e3d-b064-60af9b905dae"
   },
   "outputs": [],
   "source": [
    "len(res['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58eaf5ec-ee4c-4a1b-8178-5171d49e60ec",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-zraDCjNeC6",
    "outputId": "a7c79486-6fb4-4bc6-efec-320e9f525766"
   },
   "outputs": [],
   "source": [
    "len(res['data'][0]['embedding']), len(res['data'][1]['embedding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a6616e2-fa5f-49f8-946d-2b799ea4c072",
     "showTitle": false,
     "title": ""
    },
    "id": "XPd41MjANhmp"
   },
   "source": [
    "We will apply this same embedding logic to the langchain docs dataset we've just scraped. But before doing so we must create a place to store the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6bdb846-ebeb-4953-8246-a8f95146d404",
     "showTitle": false,
     "title": ""
    },
    "id": "WPi4MZvMNvUH"
   },
   "source": [
    "## Initializing the Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46612333-5ab6-435a-b4b5-fce5ce4750bf",
     "showTitle": false,
     "title": ""
    },
    "id": "H5RRQArrN2lN"
   },
   "source": [
    "Now we need a place to store these embeddings and enable a efficient vector search through them all. To do that we use Pinecone, we can get a [free API key](https://app.pinecone.io/) and enter it below where we will initialize our connection to Pinecone and create a new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3c597d2-eeb5-411f-89c2-5a6eefd3a010",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EO8sbJFZNyIZ",
    "outputId": "f2d2efca-65be-47ea-ab1d-1dab2786a6b9"
   },
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "index_name = 'gpt-4-langchain-docs'\n",
    "\n",
    "# initialize connection to pinecone\n",
    "pinecone.init(\n",
    "    api_key=\"PINECONE_API_KEY\",  # app.pinecone.io (console)\n",
    "    environment=\"PINECONE_ENVIRONMENT\"  # next to API key in console\n",
    ")\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # if does not exist, create index\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dimension=len(res['data'][0]['embedding']),\n",
    "        metric='dotproduct'\n",
    "    )\n",
    "# connect to index\n",
    "index = pinecone.GRPCIndex(index_name)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7624358d-3f06-4c70-b15f-89cb06113c4f",
     "showTitle": false,
     "title": ""
    },
    "id": "ezSTzN2rPa2o"
   },
   "source": [
    "We can see the index is currently empty with a `total_vector_count` of `0`. We can begin populating it with OpenAI `text-embedding-ada-002` built embeddings like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01f563cf-ecc8-47e3-82c2-2e6b03f8886e",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b6b5865b02504e10a020ad5f42241df6",
      "b1489d5d6c1f498fadaea8aeb16ab60f",
      "90aa35cbdf0c45a1bb7b9075c48a6f7d",
      "70eaf7d1a5b24e49a32490fd3a75ea15",
      "144e2e3c8a014c549e0f552a64a670ef",
      "e5b49411f2134a9b9649528314f746d6",
      "7d78613ce91b4427a4afacb699ef031e",
      "1b93eb9d358041ab99fe87045f7f0660",
      "af4f336bfcb446afb9e6a513d49d791f",
      "a9552f4dca1642e2924ee152067f1f3d",
      "c82f8fbcef0648489f1dcbb4af5ea8c4"
     ]
    },
    "id": "iZbFbulAPeop",
    "outputId": "a017780a-19d0-4e6f-a68c-529c0c96e4f8"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import datetime\n",
    "from time import sleep\n",
    "\n",
    "batch_size = 100  # how many embeddings we create and insert at once\n",
    "\n",
    "for i in tqdm(range(0, len(chunks), batch_size)):\n",
    "    # find end of batch\n",
    "    i_end = min(len(chunks), i+batch_size)\n",
    "    meta_batch = chunks[i:i_end]\n",
    "    # get ids\n",
    "    ids_batch = [x['id'] for x in meta_batch]\n",
    "    # get texts to encode\n",
    "    texts = [x['text'] for x in meta_batch]\n",
    "    # create embeddings (try-except added to avoid RateLimitError)\n",
    "    try:\n",
    "        res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "    except:\n",
    "        done = False\n",
    "        while not done:\n",
    "            sleep(5)\n",
    "            try:\n",
    "                res = openai.Embedding.create(input=texts, engine=embed_model)\n",
    "                done = True\n",
    "            except:\n",
    "                pass\n",
    "    embeds = [record['embedding'] for record in res['data']]\n",
    "    # cleanup metadata\n",
    "    meta_batch = [{\n",
    "        'text': x['text'],\n",
    "        'chunk': x['chunk'],\n",
    "        'url': x['url']\n",
    "    } for x in meta_batch]\n",
    "    to_upsert = list(zip(ids_batch, embeds, meta_batch))\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=to_upsert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "970767fc-686f-4d60-ae01-ba8e41544c78",
     "showTitle": false,
     "title": ""
    },
    "id": "YttJOrEtQIF9"
   },
   "source": [
    "Now we've added all of our langchain docs to the index. With that we can move on to retrieval and then answer generation using GPT-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a8b816b-ad47-422c-885b-e4fce9f7b028",
     "showTitle": false,
     "title": ""
    },
    "id": "FumVmMRlQQ7w"
   },
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3e06c2c-a49c-4ebf-bc64-a1f57b24ba9d",
     "showTitle": false,
     "title": ""
    },
    "id": "nLRODeL-QTJ9"
   },
   "source": [
    "To search through our documents we first need to create a query vector `xq`. Using `xq` we will retrieve the most relevant chunks from the LangChain docs, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a821a850-288d-4055-969e-523357ebc7f7",
     "showTitle": false,
     "title": ""
    },
    "id": "FMUPdX9cQQYC"
   },
   "outputs": [],
   "source": [
    "query = \"how do I use the LLMChain in LangChain?\"\n",
    "\n",
    "res = openai.Embedding.create(\n",
    "    input=[query],\n",
    "    engine=embed_model\n",
    ")\n",
    "\n",
    "# retrieve from Pinecone\n",
    "xq = res['data'][0]['embedding']\n",
    "\n",
    "# get relevant contexts (including the questions)\n",
    "res = index.query(xq, top_k=5, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "420c15f3-cd8c-44f9-b50e-dcbce47f18c0",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zl9SrFPkQjg-",
    "outputId": "86a8c598-15d1-4ad1-db32-6db2b3e0af1e"
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "451e152d-2d8e-45b0-93af-19feb882b02a",
     "showTitle": false,
     "title": ""
    },
    "id": "MoBSiDLIUADZ"
   },
   "source": [
    "With retrieval complete, we move on to feeding these into GPT-4 to produce answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f548b416-f420-452a-a9d1-ffffb613328b",
     "showTitle": false,
     "title": ""
    },
    "id": "qfzS4-6-UXgX"
   },
   "source": [
    "## Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "381e66b1-054f-4b5d-94ce-c30794978782",
     "showTitle": false,
     "title": ""
    },
    "id": "XPC1jQaKUcy0"
   },
   "source": [
    "GPT-4 is currently accessed via the `ChatCompletions` endpoint of OpenAI. To add the information we retrieved into the model, we need to pass it into our user prompts *alongside* our original query. We can do that like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d6c602c-7064-4431-9e07-db74bca24567",
     "showTitle": false,
     "title": ""
    },
    "id": "unZstoHNUHeG"
   },
   "outputs": [],
   "source": [
    "# get list of retrieved text\n",
    "contexts = [item['metadata']['text'] for item in res['matches']]\n",
    "\n",
    "augmented_query = \"\\n\\n---\\n\\n\".join(contexts)+\"\\n\\n-----\\n\\n\"+query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a8b2b0a-5e53-4e4a-bf3b-2664bb529433",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRcEHm0Z9fXE",
    "outputId": "872a7f7e-2001-44b5-ff44-cb045365a515"
   },
   "outputs": [],
   "source": [
    "print(augmented_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9dd9157-a1a0-4c98-a794-d108c70ea969",
     "showTitle": false,
     "title": ""
    },
    "id": "sihH_GMiV5_p"
   },
   "source": [
    "Now we ask the question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43704cec-c531-4e58-8442-331a6265a4e6",
     "showTitle": false,
     "title": ""
    },
    "id": "IThBqBi8V70d"
   },
   "outputs": [],
   "source": [
    "# system message to 'prime' the model\n",
    "primer = f\"\"\"You are Q&A bot. A highly intelligent system that answers\n",
    "user questions based on the information provided by the user above\n",
    "each question. If the information can not be found in the information\n",
    "provided by the user you truthfully say \"I don't know\".\n",
    "\"\"\"\n",
    "\n",
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": primer},\n",
    "        {\"role\": \"user\", \"content\": augmented_query}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "403836be-1da3-4034-8fa1-d4f070afef0d",
     "showTitle": false,
     "title": ""
    },
    "id": "QvS1yJhOWpiJ"
   },
   "source": [
    "To display this response nicely, we will display it in markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf7d2193-f7fe-4365-98e1-a85e79958877",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "RDo2qeMHWto1",
    "outputId": "26d30abb-767a-4256-cd48-50af20128c84"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e3bf96d-c69c-4d2a-b42a-d81e92362d9e",
     "showTitle": false,
     "title": ""
    },
    "id": "eJ-a8MHg0eYQ"
   },
   "source": [
    "Let's compare this to a non-augmented query..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01398b50-6b7f-405f-a211-b27e100770dd",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 46
    },
    "id": "vwhaSgdF0ZDX",
    "outputId": "7a139208-bc40-4784-fae8-a10caf09800e"
   },
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": primer},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    ")\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab53aa34-9914-42ee-8920-48389693076d",
     "showTitle": false,
     "title": ""
    },
    "id": "5CSsA-dW0m_P"
   },
   "source": [
    "If we drop the `\"I don't know\"` part of the `primer`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40ff4d81-3227-41ef-9b6a-b8e9d84a8a07",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "Z3svdTCZ0iJ2",
    "outputId": "e6a8c0bf-e575-454c-bd20-e3b1db3e47b0"
   },
   "outputs": [],
   "source": [
    "res = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are Q&A bot. A highly intelligent system that answers user questions\"},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    ")\n",
    "display(Markdown(res['choices'][0]['message']['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3826f35f-92dc-4d45-8842-f7fc3884003b",
     "showTitle": false,
     "title": ""
    },
    "id": "kqDEXo3c0w1K"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "GPT4_Retrieval_Augmentation",
   "notebookOrigID": 1572001650642367,
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04fd6e9cebaa4c9287d16cb8c861c8a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "144e2e3c8a014c549e0f552a64a670ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "153f898146264d50b77b5ef23db92408": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bed5d4ebf054e80b4d63d6f8a2593d8",
      "placeholder": "​",
      "style": "IPY_MODEL_04fd6e9cebaa4c9287d16cb8c861c8a3",
      "value": " 231/231 [00:01&lt;00:00, 193.80it/s]"
     }
    },
    "157f79e1ecf0423393cb15dcd2e66996": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b93eb9d358041ab99fe87045f7f0660": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bed5d4ebf054e80b4d63d6f8a2593d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30d7236e54844058b7c76404e1f2ccb8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "348fe1bd02ed4dca8df422031d1184f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70eaf7d1a5b24e49a32490fd3a75ea15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9552f4dca1642e2924ee152067f1f3d",
      "placeholder": "​",
      "style": "IPY_MODEL_c82f8fbcef0648489f1dcbb4af5ea8c4",
      "value": " 12/12 [00:18&lt;00:00,  3.12s/it]"
     }
    },
    "7d78613ce91b4427a4afacb699ef031e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "865d0f1e70cc4889aaf91cf1ad82b909": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8f0edead487948358efe478a01316209": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_348fe1bd02ed4dca8df422031d1184f6",
      "placeholder": "​",
      "style": "IPY_MODEL_157f79e1ecf0423393cb15dcd2e66996",
      "value": "100%"
     }
    },
    "90aa35cbdf0c45a1bb7b9075c48a6f7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b93eb9d358041ab99fe87045f7f0660",
      "max": 12,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_af4f336bfcb446afb9e6a513d49d791f",
      "value": 12
     }
    },
    "a43a7db5cab149b3a8aeef23d3fb936f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9552f4dca1642e2924ee152067f1f3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af4f336bfcb446afb9e6a513d49d791f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b1489d5d6c1f498fadaea8aeb16ab60f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5b49411f2134a9b9649528314f746d6",
      "placeholder": "​",
      "style": "IPY_MODEL_7d78613ce91b4427a4afacb699ef031e",
      "value": "100%"
     }
    },
    "b6b5865b02504e10a020ad5f42241df6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b1489d5d6c1f498fadaea8aeb16ab60f",
       "IPY_MODEL_90aa35cbdf0c45a1bb7b9075c48a6f7d",
       "IPY_MODEL_70eaf7d1a5b24e49a32490fd3a75ea15"
      ],
      "layout": "IPY_MODEL_144e2e3c8a014c549e0f552a64a670ef"
     }
    },
    "bcd3e274345a44dc950890c1fa1026a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a43a7db5cab149b3a8aeef23d3fb936f",
      "max": 231,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_865d0f1e70cc4889aaf91cf1ad82b909",
      "value": 231
     }
    },
    "c82f8fbcef0648489f1dcbb4af5ea8c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5b49411f2134a9b9649528314f746d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe4aa5160ef74ecd820f9c6f7de035a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8f0edead487948358efe478a01316209",
       "IPY_MODEL_bcd3e274345a44dc950890c1fa1026a7",
       "IPY_MODEL_153f898146264d50b77b5ef23db92408"
      ],
      "layout": "IPY_MODEL_30d7236e54844058b7c76404e1f2ccb8"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
